{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a mix of stats and sentance similar to predict course purchases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm, trange\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import *\n",
    "\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "tokenizer = SentenceTransformer('shibing624/text2vec-base-chinese')\n",
    "user = load_from_pickle('../data/user')\n",
    "course = load_from_pickle('../data/course')\n",
    "\n",
    "df_test = pd.read_csv(\"../data/test_unseen.csv\")\n",
    "df_test = convert_test(df_test,user)\n",
    "de = df_test['text'].to_list()\n",
    "eval_embeddings = [tokenizer.encode(i) for i in tqdm(de)]\n",
    "course_list = course.course_name.to_list()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set the candidate course by course_filter result\n",
    "* get target course embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = list(set(\n",
    "       [686, 699, 501, 500, 502, 656, 665]\n",
    "       ))\n",
    "course_top = [course_list[i] for i in candidate]\n",
    "course_embeddings = [tokenizer.encode(i) for i in tqdm(course_top)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = []\n",
    "for i,k in tqdm(enumerate(eval_embeddings)):\n",
    "    prob_index = util.pytorch_cos_sim(eval_embeddings[i],course_embeddings).squeeze(0).argsort(descending=True).tolist()\n",
    "    prob = [candidate[i] for i in prob_index]\n",
    "    ans.append(list(dict.fromkeys(prob))[:])\n",
    "ans_ = [list(map(lambda x:list(course.index)[x],ans[i])) for i in range(len(ans))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# delete seen course from predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = load_from_pickle('../data/train')\n",
    "seen = {i:k.split(' ') for i,k in zip(seen.user_id,seen.course_id)}\n",
    "for i,user in enumerate(df_test['user_id'].values):\n",
    "    if(user in seen.keys()):\n",
    "        ans_[i] = [x for x in ans_[i] if x not in seen[user]]\n",
    "ans_ = [\" \".join(item) for item in ans_]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'user_id':df_test['user_id'].to_list(),\n",
    "    'course_id':ans_\n",
    "}\n",
    "pd.DataFrame(data).to_csv('./top7.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b8342dc7eb55f317299c826e768d4a74448ec8e4c3c130a975dcf70ffcf0999"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
